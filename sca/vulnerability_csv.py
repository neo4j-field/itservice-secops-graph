# this script can read Software Bill of Material (SBOM) data in the CycloneDX
# format and create a CSV file that can be imported with Cypher
import csv
import json
import os
import sys
from os import PathLike
import logging

logging.basicConfig(level=logging.DEBUG, format="%(asctime)s %(levelname)s %(message)s")


class VulnerabilityData:
    def __init__(self):
        self._data = {}  # vulnerability -> component purl

    def transform(self, folder: PathLike):
        self.__read_dir(folder)
        self.__output_csv("../data/component-vulnerability.csv")

    def __read_dir(self, folder: PathLike):
        logging.info(f"Reading Trivy reports from {folder}")

        try:
            files = [f for f in os.listdir(folder)]
            logging.info(f"Files in {folder}: {files}")

        except FileNotFoundError:
            logging.critical(f"Cannot read directory {folder}")
            sys.exit(1)

        for file in os.listdir(folder):
            if file.endswith("_trivy.json"):
                try:
                    with open(os.path.join(folder, file), "r") as f:
                        data = json.load(f)
                        self.__process_trivy_report(file, data)

                except json.JSONDecodeError:
                    logging.warning(f"Cannot read Trivy file {file}")

    @staticmethod
    def __extract_from_filename(filename: str) -> dict:
        vals = filename.split("_")
        app_name = vals[0]
        app_version = vals[1]

        return {"name": app_name, "app_version": app_version}

    # read a single SBOM in CycloneDX format and save the fields we want
    def __process_trivy_report(self, filename: str, data: dict):
        logging.info(f"Processing Trivy report {filename}")

        # extract the application name and version info from the filename
        meta_data = self.__extract_from_filename(filename)

        # add more data from the SBOM
        meta_data["date"] = data["CreatedAt"]
        meta_data["source"] = "trivy"

        # walk through vulnerabilities
        for result_set in data["Results"]:
            for v in result_set["Vulnerabilities"]:
                vdata = {
                    "date": meta_data["date"],
                    "source": meta_data["source"],
                }
                vulnerability_id = v["VulnerabilityID"]

                # skip if we already processed it in another report
                if vulnerability_id in self._data:
                    continue

                vdata["vulnerability_id"] = v["VulnerabilityID"]
                vdata["purl"] = v["PkgIdentifier"]["PURL"]
                vdata["severity"] = v["Severity"].lower()
                vdata["title"] = v["Title"]
                vdata["link"] = v["PrimaryURL"]
                vdata["status"] = v["Status"]
                vdata["fixed_version"] = v.get("FixedVersion", "")
                vdata["published_date"] = v.get("PublishedDate", "")

                # cvss scores not always available
                vdata["cvss_v3"] = ""
                if "CVSS" in v:
                    for k, v in v["CVSS"].items():
                        if not vdata.get("cvss_v3") and v.get("V3Score"):
                            vdata["cvss_v3"] = v.get("V3Score")

                self._data[vulnerability_id] = vdata

    # store a CSV output file with all the SCA data we extracted
    def __output_csv(self, filename: str):
        logging.info(f"Writing SBOM data to {filename}")

        fields = ["date", "source", "vulnerability_id", "purl", "severity", "title", "link", "status", "fixed_version", "published_date", "cvss_v3"]
        try:
            dictwriter = csv.DictWriter(open(filename, "w"), fieldnames=fields, quoting=csv.QUOTE_ALL, delimiter=";")
            dictwriter.writeheader()
            dictwriter.writerows(self._data.values())
        except IOError:
            logging.critical(f"Cannot write to {filename}")
            sys.exit(1)

if __name__ == "__main__":
    sbom_data = VulnerabilityData()
    sbom_data.transform(sys.argv[1])
